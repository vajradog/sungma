# Claude Code Prompt â€” Sungma Phase 1 Build

## Copy everything below this line and paste into Claude Code:

---

Read the file `SPEC.md` in this repo for full project context. You are building **Sungma (à½¦à¾²à½´à½„à¼‹à½˜)**, a free, open-source, browser-based privacy camera for activists. Everything runs client-side. No backend. Hosted on GitHub Pages.

## Project Setup

- Create a vanilla HTML/CSS/JS project (no framework, no build step â€” must deploy directly to GitHub Pages)
- Single `index.html` entry point with modular JS files
- Mobile-first responsive design, dark mode default
- PWA with `manifest.json` and `service-worker.js` for offline support and "Add to Home Screen"
- All dependencies loaded via CDN (no npm, no bundler):
  - TensorFlow.js: `https://cdn.jsdelivr.net/npm/@tensorflow/tfjs`
  - BlazeFace: `https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface`
  - piexifjs: `https://cdn.jsdelivr.net/npm/piexifjs` (for EXIF writing)
  - exifr: `https://cdn.jsdelivr.net/npm/exifr` (for EXIF reading from uploads)

## File Structure

```
sungma/
â”œâ”€â”€ index.html              # Main app shell
â”œâ”€â”€ manifest.json           # PWA manifest
â”œâ”€â”€ service-worker.js       # Offline caching
â”œâ”€â”€ css/
â”‚   â””â”€â”€ style.css           # All styles, mobile-first, dark mode
â”œâ”€â”€ js/
â”‚   â”œâ”€â”€ app.js              # Main app initialization and UI state
â”‚   â”œâ”€â”€ camera.js           # Camera stream management (front/rear toggle)
â”‚   â”œâ”€â”€ detection.js        # TensorFlow.js BlazeFace face detection
â”‚   â”œâ”€â”€ pixelation.js       # Canvas rendering with pixelation overlay
â”‚   â”œâ”€â”€ recorder.js         # MediaRecorder for video + audio recording
â”‚   â”œâ”€â”€ audio.js            # Voice distortion via Web Audio API
â”‚   â”œâ”€â”€ metadata.js         # EXIF stripping, GPS/timestamp preservation, proof embedding
â”‚   â”œâ”€â”€ photo.js            # Photo capture and export
â”‚   â”œâ”€â”€ share.js            # Download and Web Share API
â”‚   â””â”€â”€ utils.js            # Helpers, canvas fingerprint noise, etc.
â”œâ”€â”€ icons/                  # PWA icons (192x192, 512x512)
â”œâ”€â”€ SPEC.md                 # Full project specification
â””â”€â”€ README.md               # Project readme
```

## Phase 1 Features to Build

### 1. Live Camera with Face Pixelation
- Use `navigator.mediaDevices.getUserMedia()` to access camera
- Default to rear camera, toggle button for front/rear
- Feed camera stream into a hidden `<video>` element
- Run BlazeFace detection on each frame (~15-30fps depending on device)
- Draw each frame to a `<canvas>` element
- For each detected face bounding box, pixelate that region on the canvas:
  - Read the pixel data in the face region
  - Divide into blocks (e.g., 10x10 pixels)
  - Average the color of each block
  - Fill the block with the averaged color
- The canvas is what the user sees â€” the raw video is never displayed

### 2. Photo Capture
- Tap shutter button â†’ capture current canvas frame as PNG
- Use `canvas.toBlob()` for the export
- Before saving, run metadata processing (see section 6)
- Show captured photo preview with save/share/discard options

### 3. Video Recording
- Use `MediaRecorder` API on `canvas.captureStream(30)` (30fps)
- Record audio from the microphone simultaneously
- If voice distortion is enabled, pipe audio through Web Audio API before recording
- Combine pixelated video + (optionally distorted) audio into single recording
- Show recording indicator (red dot + timer)
- Stop recording â†’ show preview with save/share/discard
- Output format: WebM (widest MediaRecorder support)

### 4. Audio-Only Recording
- Separate mode for voice-only testimony
- MediaRecorder on audio stream only
- Optional voice distortion toggle
- Output as .ogg or .webm audio

### 5. Voice Distortion
- Web Audio API: `createScriptProcessor` or `AudioWorklet`
- Pitch shift down by configurable amount (subtle, medium, heavy presets)
- Apply to both live preview (so user hears themselves distorted) and recording
- Toggle on/off in UI

### 6. Smart Metadata Handling
- **For photos captured via canvas:** Canvas `.toBlob()` exports produce clean files with zero EXIF. This is our baseline â€” automatically safe.
- **GPS preservation:** Use `navigator.geolocation.getCurrentPosition()` to get current GPS. Use piexifjs to write ONLY these EXIF fields into the exported PNG/JPEG:
  - GPSLatitude, GPSLongitude
  - GPSAltitude (if available)
  - GPSImgDirection (if available)
  - DateTimeOriginal
- **User toggles in settings:**
  - "Include GPS location" (default: ON)
  - "Include date/time" (default: ON)
- **For uploaded files (Phase 2):** Read EXIF with exifr, extract GPS+timestamp, strip everything, re-embed only GPS+timestamp with piexifjs.

### 7. Embedded Proof Data
- After creating the final image/video file, embed invisible proof data:
- **For PNG:** Use PNG tEXt chunk. Write a custom text chunk with key "sungma-proof" containing a JSON string:
  ```json
  {
    "v": "1.0.0",
    "hash": "sha256:abc123...",
    "gps": [27.7172, 85.3240],
    "time": "2026-02-23T14:30:07Z",
    "note": "user note if provided"
  }
  ```
- **Hash calculation:** Use `crypto.subtle.digest('SHA-256', fileBuffer)` on the image data BEFORE embedding the proof (hash the pixel content, then embed the hash)
- **Optional encryption:** If user sets a passphrase, encrypt the proof JSON with AES-256-GCM via Web Crypto API before embedding. The embedded data then looks like random bytes.
- **For video (WebM):** Store proof as a Matroska tag or as a custom metadata field. If this is too complex for MVP, write proof to a `.sungma` JSON sidecar file that downloads alongside the video.

### 8. Canvas Fingerprint Protection
- Before exporting any image, inject random noise into the least significant bits of a small number of random pixels
- This prevents canvas fingerprinting (where GPU rendering differences can identify a device)
- The noise is imperceptible to the human eye
- Implementation: iterate over a random 1-2% of pixels in the ImageData, and flip the LSB of one color channel randomly

### 9. PWA / Offline Support
- `manifest.json` with:
  - name: "Sungma"
  - short_name: "Sungma"
  - description: "Privacy camera for activists"
  - theme_color: dark theme color
  - display: "standalone"
  - icons at 192x192 and 512x512
- `service-worker.js`:
  - Cache all app assets on install (HTML, CSS, JS, TF.js model files)
  - Serve from cache first, fall back to network
  - The app must work fully offline after first load (camera, pixelation, photo/video capture, save to device)
  - Only GPS geolocation requires network (graceful fallback: just skip GPS if offline)

### 10. UI / UX Design
- **Dark mode default** â€” less conspicuous in the field
- **Mobile-first** â€” designed for phones held vertically
- **Minimal UI** â€” camera viewfinder takes up most of the screen
- **Large touch targets** â€” big buttons for high-stress use
- **Layout:**
  ```
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Sungma  [âš™ï¸] [ğŸ”„ cam]      â”‚  â† Header: settings, camera toggle
  â”‚                             â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
  â”‚  â”‚                       â”‚  â”‚
  â”‚  â”‚   Canvas viewfinder   â”‚  â”‚  â† Full-width pixelated preview
  â”‚  â”‚   (faces pixelated)   â”‚  â”‚
  â”‚  â”‚                       â”‚  â”‚
  â”‚  â”‚   "2 faces detected"  â”‚  â”‚  â† Subtle face count indicator
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
  â”‚                             â”‚
  â”‚  [ğŸ¤ Distort: OFF]          â”‚  â† Voice distortion toggle
  â”‚                             â”‚
  â”‚  [ğŸ“¸]    [âºï¸ Record]   [ğŸ¤]  â”‚  â† Photo / Video / Audio buttons
  â”‚                             â”‚
  â”‚  [ğŸ“‹ Settings panel]        â”‚  â† Expandable: GPS toggle, timestamp,
  â”‚                             â”‚     proof passphrase, etc.
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  ```
- **Settings panel** (expandable from bottom or gear icon):
  - GPS location: ON/OFF toggle
  - Date/time: ON/OFF toggle
  - Voice distortion: OFF / Subtle / Medium / Heavy
  - Proof passphrase: text input (optional)
  - Event note: text input (optional)
  - About / Version info
- **After capture, show preview overlay:**
  - Captured photo/video preview
  - [âœ… Save] [ğŸ“¤ Share] [ğŸ—‘ï¸ Discard]
  - File size indicator
- **Color palette:**
  - Background: #0a0a0a (near-black)
  - Primary accent: #10b981 (green â€” safe, protective)
  - Text: #e5e5e5 (light gray)
  - Danger/recording: #ef4444 (red)
  - Borders/subtle: #262626

## Important Technical Notes

1. **BlazeFace model loading:** The TF.js model needs to be loaded once on app start. Show a loading indicator. Cache the model via service worker for offline use. The model is small (~200KB).

2. **Performance:** BlazeFace is fast but canvas redraw at 30fps with pixelation can be heavy on low-end phones. Implement frame skipping â€” run detection every 2-3 frames and reuse the last known face positions for intermediate frames.

3. **Camera permissions:** Handle all permission states gracefully â€” prompt, granted, denied. Show clear instructions if denied.

4. **MediaRecorder codec support:** Different browsers support different codecs. Try `video/webm;codecs=vp9,opus` first, fall back to `video/webm;codecs=vp8,opus`, then `video/webm`. Check `MediaRecorder.isTypeSupported()`.

5. **Memory management:** For long video recordings, the MediaRecorder stores data in memory. Implement chunked recording â€” save chunks periodically to avoid out-of-memory crashes on mobile. Use `ondataavailable` with a timeslice parameter.

6. **Canvas toBlob for PNG with tEXt chunks:** The standard `canvas.toBlob()` won't let you add custom PNG chunks. You'll need to manually construct the PNG binary â€” take the blob output, parse the PNG structure, inject a tEXt chunk before the IEND chunk, and create a new blob. There are lightweight libraries for this, or write a small PNG chunk injector.

7. **HTTPS required:** Both `getUserMedia` (camera) and `navigator.geolocation` require HTTPS. GitHub Pages provides this automatically.

8. **Do not include any analytics, tracking, telemetry, or external requests** beyond the CDN-loaded libraries. The app must be fully self-contained after initial load.

## What NOT to Build Yet

- No user accounts or authentication
- No server-side anything
- No file upload/pixelate (that's Phase 2)
- No body detection (Phase 2)
- No interview split-screen mode (Phase 2)
- No cloud upload or P2P sharing (Phase 3)
- No panic button or stealth mode (Phase 4)
- No organization channels (Phase 5)

## Deliverable

A fully functional PWA that:
1. Opens the camera with real-time face pixelation
2. Captures pixelated photos with clean metadata + embedded proof
3. Records pixelated video with optional voice distortion
4. Records audio-only with optional distortion
5. Saves to device and shares via native share sheet
6. Works offline after first visit
7. Is installable as a PWA
8. Looks clean, professional, and works well on mobile

Start by setting up the project structure and index.html, then implement the camera + face detection + pixelation pipeline first â€” that's the core of everything else.
